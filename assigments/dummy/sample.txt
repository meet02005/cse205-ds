Why do matrices represent linear maps?

For illustration, consider an example for  2×2matrices representing linear maps from  R^2→R^2. Any vector in a two-dimensional vector space can be uniquely written as a linear combination of two basis vectors, i.e.,  ux+vywhere  u,v are scalars and  x,y are linearly independent two-dimensional vectors and hence a basis set in 2 dimensions. If  f:R^2→R^2is linear, then from the definition of linearity
f(ux+vy)=uf(x)+vf(y)
 . Note that  f(x),f(y) are vectors as well, so they can also be written uniquely as linear combinations of the basis vectors
f(x)=ax+cy
 
f(y)=bx+dy,
where  a,b,c,d are scalars. Substituting these expressions into the equation above, you get
f(ux+vy)=uax+ucy+vbx+vdy
 
which can be simplified to
(ua+vb)x+(uc+vd)y
 .
The scalar terms may look familiar - they are the expressions for multiplication of a column vector by a matrix! Since we know that any vector is uniquely determined as a linear combination of basis vectors, if we fix the basis vectors, then all we need to keep track of are the scalars. That is, the coordinate column vector our original vector  ux+vy in terms of the basis  x,y are [uv].
The matrix is made up of the coordinates of each of the basis vectors in the order we have chosen. Since  u
  was the scalar corresponding to  x, this is the first basis vector, so the first column of the matrix should be the coordinate column vector of  f(x)
  which from  f(x)=ax+cy
  is [ac]
 
Likewise, the second column of the matrix is the coordinate column vector of  f(y)=bx+dy
  which is [bd]
 .
Now put these together as a matrix-vector product:
[acbd][uv]=[ua+vbuc+vd]
 
which is consistent with what we found above. So basically, matrices act as a short-hand for a linear transformation by storing the coordinates of that transform for each of the (fixed) vectors in an ordered basis set.

This example is for linear functions from  R2→R2
 , but it works exactly the same way for transformations between other finite-dimensional spaces.